{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import Dict, Any\n",
    "\n",
    "def create_prompt_chains(llm) -> Dict[str, Any]:\n",
    "    # Initial Response Prompt\n",
    "    initial_response_template = ChatPromptTemplate.from_messages([\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"You are a fact-checking assistant. Provide a preliminary answer to the following claim or question.\n",
    "            Be concise but include key points that would need verification.\n",
    "            \n",
    "            Claim: {claim}\n",
    "            \n",
    "            Preliminary Answer:\"\"\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Assumption Verification Prompt\n",
    "    assumption_verification_template = ChatPromptTemplate.from_messages([\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Evaluate the truthfulness of this assumption based on the provided search results:\n",
    "            \n",
    "            Assumption: {assumption}\n",
    "            \n",
    "            Search Results:\n",
    "            {search_results}\n",
    "            \n",
    "            Your evaluation should be one of:\n",
    "            - TRUE: The assumption is supported by evidence\n",
    "            - FALSE: The assumption is contradicted by evidence\n",
    "            - UNCERTAIN: The evidence is inconclusive\n",
    "            \n",
    "            Provide a brief explanation for your evaluation.\n",
    "            \n",
    "            Evaluation:\"\"\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Final Synthesis Prompt\n",
    "    final_synthesis_template = ChatPromptTemplate.from_messages([\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Synthesize a final fact-checked response based on the original claim, initial response, and verified assumptions.\n",
    "            \n",
    "            Original Claim: {claim}\n",
    "            Initial Response: {initial_response}\n",
    "            \n",
    "            Verified Assumptions:\n",
    "            {verified_assumptions}\n",
    "            \n",
    "            Final Fact-Checked Response:\"\"\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"initial_response\": LLMChain(llm=llm, prompt=initial_response_template),\n",
    "        \"assumption_verification\": LLMChain(llm=llm, prompt=assumption_verification_template),\n",
    "        \"final_synthesis\": LLMChain(llm=llm, prompt=final_synthesis_template)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
