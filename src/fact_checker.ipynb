{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from typing import List, Dict, Any\n",
    "from .prompt_chains import create_prompt_chains\n",
    "from .search_tools import WebSearchTool\n",
    "from .utils import extract_assumptions, validate_assumptions\n",
    "import logging\n",
    "\n",
    "class FactCheckerBot:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=Settings.MODEL_NAME,\n",
    "            temperature=Settings.TEMPERATURE,\n",
    "            max_tokens=Settings.MAX_TOKENS,\n",
    "            openai_api_key=Settings.OPENAI_API_KEY\n",
    "        )\n",
    "        self.prompt_chains = create_prompt_chains(self.llm)\n",
    "        self.search_tool = WebSearchTool()\n",
    "        \n",
    "    def check_fact(self, claim: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            # Step 1: Initial Response\n",
    "            initial_response = self._get_initial_response(claim)\n",
    "            \n",
    "            # Step 2: Assumption Extraction\n",
    "            assumptions = extract_assumptions(initial_response)\n",
    "            \n",
    "            # Step 3: Verification Loop\n",
    "            verified_assumptions = []\n",
    "            for assumption in assumptions:\n",
    "                verification = self._verify_assumption(assumption)\n",
    "                verified_assumptions.append(verification)\n",
    "            \n",
    "            # Step 4: Final Synthesis\n",
    "            final_response = self._synthesize_response(claim, initial_response, verified_assumptions)\n",
    "            \n",
    "            return {\n",
    "                \"claim\": claim,\n",
    "                \"initial_response\": initial_response,\n",
    "                \"assumptions\": verified_assumptions,\n",
    "                \"final_response\": final_response,\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in fact-checking: {str(e)}\")\n",
    "            return {\n",
    "                \"claim\": claim,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"failed\"\n",
    "            }\n",
    "    \n",
    "    def _get_initial_response(self, claim: str) -> str:\n",
    "        chain = self.prompt_chains[\"initial_response\"]\n",
    "        return chain.run(claim=claim)\n",
    "    \n",
    "    def _verify_assumption(self, assumption: str) -> Dict[str, Any]:\n",
    "        # Check if assumption is already a known fact\n",
    "        validation = validate_assumptions(assumption)\n",
    "        if validation[\"is_verified\"]:\n",
    "            return {\n",
    "                \"assumption\": assumption,\n",
    "                \"verification\": validation[\"verdict\"],\n",
    "                \"evidence\": \"Known fact\",\n",
    "                \"confidence\": \"high\"\n",
    "            }\n",
    "        \n",
    "        # If not, search for evidence\n",
    "        search_results = self.search_tool.search(assumption)\n",
    "        chain = self.prompt_chains[\"assumption_verification\"]\n",
    "        \n",
    "        verification = chain.run(\n",
    "            assumption=assumption,\n",
    "            search_results=search_results\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"assumption\": assumption,\n",
    "            \"verification\": verification,\n",
    "            \"evidence\": search_results,\n",
    "            \"confidence\": \"medium\" if search_results else \"low\"\n",
    "        }\n",
    "    \n",
    "    def _synthesize_response(self, claim: str, initial_response: str, assumptions: List[Dict]) -> str:\n",
    "        chain = self.prompt_chains[\"final_synthesis\"]\n",
    "        return chain.run(\n",
    "            claim=claim,\n",
    "            initial_response=initial_response,\n",
    "            verified_assumptions=assumptions\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
